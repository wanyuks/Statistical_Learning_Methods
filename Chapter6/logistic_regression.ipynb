{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第六章 逻辑斯蒂回归\n",
    "\n",
    "## 逻辑斯蒂回归模型\n",
    "\n",
    "### 逻辑斯蒂回归模型\n",
    "二项逻辑斯蒂回归模型是如下的条件概率分布：   \n",
    "<center>$P(Y=1|x)={e^{w\\cdot{x}+b}\\over1+e^{w\\cdot{x}+b}}$</center>   \n",
    "<center>$P(Y=0|x)={1\\over1+e^{w\\cdot{x}+b}}$</center>   \n",
    "为了方便，将权值向量和输入向量加以扩充，扔记作$w,x$，此时$w=(w^{(1)},w^{(2)},w^{(3)},\\cdots,w^{(n)},b)^T, x=(x^{(1)},x^{(2)},x^{(3)},\\cdots,1)^T$,这时，逻辑斯蒂回归模型如下：   \n",
    "<center>$P(Y=1|x)={e^{w\\cdot{x}}\\over1+e^{w\\cdot{x}}}$</center>\n",
    "<center>$P(Y=0|x)={1\\over1+e^{w\\cdot{x}}}$</center>   \n",
    "现考查逻辑斯蒂回归模型的特点，一个事件的几率是指该事件发生的概率与该事件不发生的概率的比值。如果一个事件发生的概率为$p$，那么该事件发生的几率为$p\\over{1-p}$,该事件发生的对数几率或logit函数是\n",
    "<center>$logit(p)=log{p\\over{1-p}}$</center>   \n",
    "对逻辑斯蒂回归而言，结合上面的公式   \n",
    "<center>$log{P(Y=1|x)\\over{1-P(Y=1|x)}}=w\\cdot x$</center>   \n",
    "   \n",
    "模型的参数估计:   \n",
    "逻辑斯蒂回归模型学习时，可以应用极大似然法估计模型参数，从而得到逻辑斯蒂回归模型。   \n",
    "设：<center>$P(Y=1|x)=\\pi(x), P(X=1|x)=1-\\pi(x)$</center>   \n",
    "则似然函数：   \n",
    "<center>$\\prod_{i=1}^N{[\\pi(x_i)]^{y_i}[1-\\pi(x_i)]^{1-y_i}}$</center>   \n",
    "对数似然函数为：   \n",
    "<center>\n",
    "$\n",
    "L(w)=\\sum_{i=1}^N{[y_ilog\\pi(x_i)+(1-y_i)log(1-\\pi(x_i))]}   \n",
    "   =\\sum_{i=1}^N{[y_i(w\\cdot x_i)-log(1+e^{w\\cdot x_i})]}\n",
    "$\n",
    "</center>   \n",
    "对$L(w)$求极大值，得到$w$的极大值。   \n",
    "逻辑斯蒂回归中通常用梯度下降法或拟牛顿法来优化目标函数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现logistic回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class LogisticRegression(object):\n",
    "    def __init__(self, max_iter=100, lr=0.01):\n",
    "        self.iter = max_iter\n",
    "        self.lr = lr\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.e ** (-x))\n",
    "\n",
    "    def data_matrix(self, X):\n",
    "        data_mat = []\n",
    "        for d in X:\n",
    "            # 对每一个数据加一个偏置项\n",
    "            data_mat.append([1.0, *d])\n",
    "        return data_mat\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # label = np.mat(y)\n",
    "        data_mat = self.data_matrix(X)  # m*n\n",
    "        self.weights = np.zeros((len(data_mat[0]), 1), dtype=np.float32)\n",
    "        for iter_ in range(self.iter):\n",
    "            for i in range(len(X)):\n",
    "                result = self.sigmoid(np.dot(data_mat[i], self.weights))\n",
    "                error = y[i] - result\n",
    "                # 更新权值\n",
    "                self.weights += self.lr * error * np.transpose([data_mat[i]])\n",
    "        print('LogisticRegression Model(learning_rate={},max_iter={})'.format(self.lr, self.iter))\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        X_test = self.data_matrix(X_test)\n",
    "        for x, y in zip(X_test, y_test):\n",
    "            result = np.dot(x, self.weights)\n",
    "            if (result > 0 and y == 1) or (result < 0 and y == 0):\n",
    "                right += 1\n",
    "        return right / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    # print(data)\n",
    "    return data[:, :2], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Model(learning_rate=0.01,max_iter=100)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "score = lr.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
