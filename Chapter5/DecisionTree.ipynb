{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五章 决策树\n",
    "### 算法5.1 （信息增益的算法）\n",
    "输入：训练集数据D和特征A；   \n",
    "输出：特征A对数据集D的信息增益$g(D,A)$;   \n",
    " (1) 计算数据集D的经验熵$H(D)$\n",
    "<center>$H(D)=-\\sum_{i=1}^n{|C_k|\\over|D|}log_2{|C_k|\\over|D|}$</center>   \n",
    "（2）计算特征A对数据集D的经验条件熵$H(D|A)$   \n",
    "<center>$H(D|A)= \\sum _{i=1}^n{|D_i|\\over|D|}H(D+i)=-\\sum_{i=1}^2{D_i\\over D}\\sum_{k=1}^K{|D_ik|\\over|D_i|}log_2{|D_ik|\\over|D_i|}$</center>   \n",
    "（3）计算信息增益   \n",
    "<center>$g(D,A)=H(D)-H(D,A)$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现信息增益算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class InformationGain(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # 计算经验熵\n",
    "    def empirical_entropy(self, y):\n",
    "        count_y = dict(Counter(y))\n",
    "        entropy = 0\n",
    "        for k,v in count_y.items():\n",
    "            entropy -= (v / len(y)) * math.log2(v / len(y))\n",
    "        return entropy\n",
    "\n",
    "    # 计算经验条件熵\n",
    "    def empirical_conditional_entropy(self, X, y):\n",
    "        features = X.shape[1]\n",
    "        conditional_entropy = {}\n",
    "        for feature in range(features):\n",
    "            feature_entropy = 0\n",
    "            X_feature = X[:, feature]\n",
    "            y_features = {}\n",
    "            for i in range(len(X_feature)):\n",
    "                if X_feature[i] not in y_features:\n",
    "                    y_features[X_feature[i]] = [y[i]]\n",
    "                else:\n",
    "                    y_features[X_feature[i]].append(y[i])\n",
    "            for y_feature in y_features.values():\n",
    "                entropy = 0\n",
    "                entropy += self.empirical_entropy(y_feature)\n",
    "                entropy *= len(y_feature) / len(y)\n",
    "                feature_entropy += entropy\n",
    "            if feature not in conditional_entropy:\n",
    "                conditional_entropy[feature] = feature_entropy\n",
    "        return conditional_entropy\n",
    "\n",
    "    # 计算信息增益\n",
    "    def information_gain(self, X, y, feature):\n",
    "        entropy = self.empirical_entropy(y)\n",
    "        conditional_entropy = self.empirical_conditional_entropy(X, y)\n",
    "        gain_entropy = entropy-conditional_entropy[feature]\n",
    "        return gain_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3算法\n",
    "算法5.2（ID3算法）    \n",
    "输入：训练数据$D$，特征集$A$，阈值$\\epsilon$;    \n",
    "输出：决策树$T$。   \n",
    "（1） 若$D$中所有的实例属于同一类$C_k$，则$T$为单节点树，并将类$C_k$作为该结点的类标记，返回$T$；   \n",
    "（2） 若$A=\\emptyset$，则$T$为单结点树，并将$D$中实例数最大的类$C_k$做为该结点的类标记，返回$T$;   \n",
    "（3） 否则，按照算法5.1计算A中各特征对D的信息增益选择信息增益最大的特征$A_g$;   \n",
    "（4） 如果$A_g$的信息增益小于阈值$\\epsilon$，则置T为单结点树，并将D中实例数最大的类$C_k$做为该结点的类标记，返回$T$;    \n",
    "（5） 否则，对$A_g$的每一可能取值$a_i$，依据$A_g=a_i$将$D$分割成若干个非空子集$D_i$，将$D_i$中实例数最大的类作为类标记，构建子结点，由结点及其子结点构成树$T$，返回$T$；   \n",
    "（6）对第$i$个结点，以$D_i$为训练集，以$A-{A_g}$为特征集，递归的调用步骤（1）~（5），得到子树$T_i$，返回$T_i$。    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "\n",
    "\n",
    "# 定义树的结点类\n",
    "class Node(object):\n",
    "    def __init__(self, root=True, label=None, feature_name=None, feature=None):\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name\n",
    "        self.feature = feature\n",
    "        self.tree = {}\n",
    "        self.result = {\n",
    "            'label:': self.label,\n",
    "            'feature': self.feature,\n",
    "            'tree': self.tree\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "\n",
    "    def add_node(self, value, node):\n",
    "        self.tree[value] = node\n",
    "\n",
    "    def predict(self, features):\n",
    "        if self.root is None:\n",
    "            return self.label\n",
    "        return self.tree[features[self.feature]].predict(features)\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self._tree = {}\n",
    "\n",
    "    '''\n",
    "    下面一部分代码就是在计算经验熵和条件熵, 和上面的有一些调整，主要是数据的输入采用DataFrame格式输入\n",
    "    '''\n",
    "\n",
    "    # 熵\n",
    "    @staticmethod\n",
    "    def calc_ent(datasets):\n",
    "        data_length = len(datasets)\n",
    "        label_count = {}\n",
    "        for i in range(data_length):\n",
    "            label = datasets[i][-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "        ent = -sum([(p / data_length) * log(p / data_length, 2)\n",
    "                    for p in label_count.values()])\n",
    "        return ent\n",
    "\n",
    "    # 经验条件熵\n",
    "    def cond_ent(self, datasets, axis=0):\n",
    "        data_length = len(datasets)\n",
    "        feature_sets = {}\n",
    "        for i in range(data_length):\n",
    "            feature = datasets[i][axis]\n",
    "            if feature not in feature_sets:\n",
    "                feature_sets[feature] = []\n",
    "            feature_sets[feature].append(datasets[i])\n",
    "        cond_ent = sum([(len(p) / data_length) * self.calc_ent(p)\n",
    "                        for p in feature_sets.values()])\n",
    "        return cond_ent\n",
    "\n",
    "        # 信息增益\n",
    "\n",
    "    @staticmethod\n",
    "    def info_gain(ent, cond_ent):\n",
    "        return ent - cond_ent\n",
    "\n",
    "    def info_gain_train(self, datasets):\n",
    "        count = len(datasets[0]) - 1\n",
    "        ent = self.calc_ent(datasets)\n",
    "        best_feature = []\n",
    "        for c in range(count):\n",
    "            c_info_gain = self.info_gain(ent, self.cond_ent(datasets, axis=c))\n",
    "            best_feature.append((c, c_info_gain))\n",
    "        # 比较大小\n",
    "        best_ = max(best_feature, key=lambda x: x[-1])\n",
    "        return best_\n",
    "\n",
    "    def train(self, train_data):\n",
    "        \"\"\"\n",
    "        input:数据集D(DataFrame格式)，特征集A，阈值eta\n",
    "        output:决策树T\n",
    "        \"\"\"\n",
    "        _, y_train, features = train_data.iloc[:, :-1], train_data.iloc[:, -1], train_data.columns[: -1]\n",
    "        # 1,若D中实例属于同一类Ck，则T为单节点树，并将类Ck作为结点的类标记，返回T\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(root=True, label=y_train.iloc[0])\n",
    "\n",
    "        # 2, 若A为空，则T为单节点树，将D中实例树最大的类Ck作为该节点的类标记，返回T\n",
    "        if len(features) == 0:\n",
    "            return Node(\n",
    "                root=True,\n",
    "                label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "\n",
    "        # 3,计算最大信息增益 同5.1,Ag为信息增益最大的特征\n",
    "        max_feature, max_info_gain = self.info_gain_train(np.array(train_data))\n",
    "        max_feature_name = features[max_feature]\n",
    "\n",
    "        # 4,Ag的信息增益小于阈值eta,则置T为单节点树，并将D中是实例数最大的类Ck作为该节点的类标记，返回T\n",
    "        if max_info_gain < self.epsilon:\n",
    "            return Node(root=True, label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "\n",
    "        # 5,构建Ag子集\n",
    "        node_tree = Node(\n",
    "            root=False, feature_name=max_feature_name, feature=max_feature)\n",
    "\n",
    "        feature_list = train_data[max_feature_name].value_counts().index\n",
    "        for f in feature_list:\n",
    "            sub_train_df = train_data.loc[train_data[max_feature_name] == f].drop([max_feature_name], axis=1)\n",
    "\n",
    "            # 6, 递归生成树\n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "\n",
    "        # pprint.pprint(node_tree.tree)\n",
    "        return node_tree\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        return self._tree\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self._tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label:': None, 'feature': 2, 'tree': {'否': {'label:': None, 'feature': 1, 'tree': {'否': {'label:': '否', 'feature': None, 'tree': {}}, '是': {'label:': '是', 'feature': None, 'tree': {}}}}, '是': {'label:': '是', 'feature': None, 'tree': {}}}}\n"
     ]
    }
   ],
   "source": [
    "datasets = np.array([['青年', '否', '否', '一般', '否'],\n",
    "                ['青年', '否', '否', '好', '否'],\n",
    "                ['青年', '是', '否', '好', '是'],\n",
    "                ['青年', '是', '是', '一般', '是'],\n",
    "                ['青年', '否', '否', '一般', '否'],\n",
    "                ['中年', '否', '否', '一般', '否'],\n",
    "                ['中年', '否', '否', '好', '否'],\n",
    "                ['中年', '是', '是', '好', '是'],\n",
    "                ['中年', '否', '是', '非常好', '是'],\n",
    "                ['中年', '否', '是', '非常好', '是'],\n",
    "                ['老年', '否', '是', '非常好', '是'],\n",
    "                ['老年', '否', '是', '好', '是'],\n",
    "                ['老年', '是', '否', '好', '是'],\n",
    "                ['老年', '是', '否', '非常好', '是'],\n",
    "                ['老年', '否', '否', '一般', '否'],\n",
    "                ])\n",
    "data_df = pd.DataFrame(datasets, columns=['年龄', '有工作', '有自己的房子', '信贷情况', '类别'])\n",
    "dt = DecisionTree()\n",
    "tree = dt.fit(data_df)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "部分代码参考：https://github.com/fengdu78/lihang-code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
